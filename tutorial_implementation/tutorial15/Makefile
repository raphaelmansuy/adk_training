# Tutorial 15: Live API and Audio - Real-Time Voice Interactions
# Makefile for development, testing, and voice assistant demos

.PHONY: help setup dev test demo clean
.PHONY: basic_demo advanced_demo multi_demo all_demos
.PHONY: lint format validate
.PHONY: live_env_check audio_deps_check live_smoke live_models_doc live_access_help direct_audio_demo

# Default environment values targeting a region that hosts Gemini Live preview.
# For Vertex AI: gemini-2.0-flash-live-preview-04-09 (from official ADK samples)
export VOICE_ASSISTANT_LIVE_MODEL ?= gemini-2.0-flash-live-preview-04-09
export GOOGLE_CLOUD_PROJECT ?= saas-app-001
export GOOGLE_GENAI_USE_VERTEXAI ?= 1
export GOOGLE_CLOUD_LOCATION ?= us-central1
export GOOGLE_GENAI_VERTEXAI_LOCATION ?= $(GOOGLE_CLOUD_LOCATION)

# Default target - show help
help:
	@echo "ğŸ™ï¸  Tutorial 15: Live API and Audio - Real-Time Voice Interactions"
	@echo ""
	@echo "ğŸ“‹ QUICK START:"
	@echo "  make setup    # Install dependencies"
	@echo "  make demo     # Run text-based demo (API key or Vertex AI)"
	@echo "  make basic_demo # Live API streaming demo (requires Vertex AI)"
	@echo ""
	@echo "ğŸ¯ DEVELOPMENT COMMANDS:"
	@echo "  make setup    # Install dependencies and package"
	@echo "  make dev      # Start ADK web interface (requires GOOGLE_API_KEY)"
	@echo "  make test     # Run comprehensive test suite"
	@echo ""
ğŸª DEMO COMMANDS:"
	@echo "  make demo              # Text-based conversation demo (no mic needed)"
	@echo "  make basic_demo_text   # Live API: TEXT input â†’ TEXT output"
	@echo "  make basic_demo_audio  # Live API: TEXT input â†’ AUDIO output (âœ… WORKS)"
	@echo "  make direct_audio_demo # Direct API: AUDIO input â†’ AUDIO output (bypasses ADK)"
	@echo "  make advanced_demo     # Advanced features (proactivity, affective dialog)"
	@echo "  make multi_demo        # Multi-agent voice coordination"
	@echo "  make check_audio       # Check audio device availability"
	@echo "  make live_smoke        # Quick Vertex Live connectivity smoke test"
	@echo "  make live_models_doc   # Show docs for supported Live API models"
	@echo "  make live_access_help  # Steps to request Gemini Live API activation"
	@echo "  make all_demos         # Run all demos sequentially"
	@echo ""
	@echo "ğŸ§¹ MAINTENANCE:"
	@echo "  make clean    # Remove cache files and artifacts"
	@echo "  make lint     # Check code quality"
	@echo "  make format   # Format code with black"
	@echo "  make validate # Run full validation suite"
	@echo ""
	@echo "ğŸ“– TUTORIAL: https://github.com/raphaelmansuy/adk_training/tree/main/tutorial_implementation/tutorial15"

# Setup environment
setup:
	@echo "ğŸ“¦ Setting up Tutorial 15 environment..."
	pip install -r requirements.txt
	pip install -e .
	@echo "âœ… Setup complete!"
	@echo "ğŸ’¡ Next steps:"
	@echo "   1. Copy .env.example to .env: cp .env.example .env"
	@echo "   2. For text demo (make demo): Add GOOGLE_API_KEY to .env"
	@echo "   3. For Live API (make basic_demo): Set GOOGLE_GENAI_USE_VERTEXAI=1 and GOOGLE_CLOUD_PROJECT"
	@echo "      Override GOOGLE_CLOUD_LOCATION if your project uses a different region"
	@echo "      Set VOICE_ASSISTANT_LIVE_MODEL to one of the supported Live API models"
	@echo "      Docs: https://ai.google.dev/gemini-api/docs/live#before_you_begin_building"
	@echo "   4. Run 'make demo' for basic text conversation"
	@echo "   5. Run 'make basic_demo' for real-time streaming"
	@echo "   6. For voice features: pip install pyaudio (optional)"

# Start ADK web interface
dev:
	@echo "ğŸŒ Starting ADK web interface..."
	@echo "ğŸ”‘ Make sure you have GOOGLE_API_KEY set in your environment"
	@echo "ğŸ™ï¸  Select 'voice_assistant' from the agent dropdown"
	@echo "ğŸ“± Visit http://localhost:8000 in your browser"
	adk web

# Run tests
test:
	@echo "ğŸ§ª Running comprehensive test suite..."
	pytest tests/ -v --cov=voice_assistant --cov-report=term-missing
	@echo "âœ… All tests completed!"

# Main demo (text-based, no microphone required)
demo:
	@echo "ğŸ¬ Running main voice assistant demo..."
	@echo "ğŸ’¬ This demo shows text-based conversation (no microphone needed)"
	@echo "ğŸ¤– Uses VoiceAssistant class with send_text() method"
	@echo "ğŸ”‘ Checking authentication..."
	@if [ -n "$$GOOGLE_GENAI_USE_VERTEXAI" ]; then \
		echo "   âœ… Using Vertex AI (project: $$GOOGLE_CLOUD_PROJECT, region: $${GOOGLE_CLOUD_LOCATION:-us-central1})"; \
		if [ -z "$$GOOGLE_CLOUD_PROJECT" ]; then \
			echo "   âš ï¸  GOOGLE_CLOUD_PROJECT not set - Vertex AI may fail"; \
		fi; \
		if [ -z "$$GOOGLE_CLOUD_LOCATION" ]; then \
			echo "   â„¹ï¸  Defaulting region to us-central1; set GOOGLE_CLOUD_LOCATION to override"; \
		fi; \
	elif [ -n "$$GOOGLE_API_KEY" ] || [ -n "$$GEMINI_API_KEY" ]; then \
		echo "   âœ… Using API Key"; \
		echo "   âš ï¸  Live API may have limitations with API keys"; \
		echo "   â„¹ï¸  Falling back to Responses API (text-only demo)"; \
		echo "   ğŸ” Fallback model: $${VOICE_ASSISTANT_TEXT_MODEL:-gemini-2.5-flash}"; \
	else \
		echo "   âš ï¸  No authentication found - demo will likely fail"; \
		echo "   ğŸ’¡ Set GOOGLE_API_KEY or configure Vertex AI"; \
	fi
	@echo "ğŸ“ Sends pre-written messages and shows responses"
	@echo "ğŸš€ Starting demo script..."
	python -m voice_assistant.demo
	@echo "âœ… Demo script finished!"

# Environment helpers for Live API demos
live_env_check:
	@echo "ğŸ©º Verifying Vertex Live environment..."
	@if [ -z "$$GOOGLE_GENAI_USE_VERTEXAI" ]; then \
		echo "   âŒ GOOGLE_GENAI_USE_VERTEXAI is not set. Export it (value 1) for Live API."; \
		echo "   ğŸ‘‰ Example: export GOOGLE_GENAI_USE_VERTEXAI=1"; \
		exit 1; \
	fi
	@if [ -z "$$GOOGLE_CLOUD_PROJECT" ]; then \
		echo "   âŒ GOOGLE_CLOUD_PROJECT is missing. Set your Vertex project id."; \
		echo "   ğŸ‘‰ Example: export GOOGLE_CLOUD_PROJECT=your-project"; \
		exit 1; \
	fi
	@if [ -z "$$GOOGLE_CLOUD_LOCATION" ]; then \
		echo "   â„¹ï¸  GOOGLE_CLOUD_LOCATION not set. Defaulting to us-central1."; \
	fi
	@if [ -z "$$VOICE_ASSISTANT_LIVE_MODEL" ]; then \
		echo "   âŒ VOICE_ASSISTANT_LIVE_MODEL not set. Choose a supported Live API model."; \
		echo "   ğŸ‘‰ Docs: https://ai.google.dev/gemini-api/docs/live#before_you_begin_building"; \
		exit 1; \
	fi
	@echo "   â€¢ Live model: $$VOICE_ASSISTANT_LIVE_MODEL"
	@python -m scripts.validate_live_model
	@echo "   âœ… Vertex Live prerequisites detected."

audio_deps_check:
	@echo "ğŸ§ Checking local audio dependencies..."
	@python scripts/check_audio_deps.py

live_smoke: live_env_check
	@echo "ğŸ§ª Running Vertex Live smoke test (text fallback)..."
	@python scripts/smoke_test.py

live_models_doc:
	@echo "ğŸ“š Supported Live API models (official docs):"
	@echo "   Half-cascade: gemini-live-2.5-flash-preview, gemini-2.0-flash-live-001"
	@echo "   Native audio (default): gemini-live-2.5-flash-preview-native-audio,"
	@echo "                gemini-2.5-flash-native-audio-preview-09-2025, gemini-2.5-flash-preview-native-audio-dialog,"
	@echo "                gemini-2.5-flash-exp-native-audio-thinking-dialog"
	@echo "   Docs: https://ai.google.dev/gemini-api/docs/live#before_you_begin_building"
	@echo "   Region availability varies; see https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-live-api"

live_access_help:
	@python -m scripts.live_access_help

# Check audio device availability
check_audio:
	@echo "ğŸ” Checking audio devices..."
	@python -m voice_assistant.audio_utils

# Basic demo with TEXT modality (fallback mode)
basic_demo_text: live_env_check
	@echo "ğŸ¯ Running Basic Live API Demo (TEXT MODE)..."
	@echo "   Demonstrates fundamental bidirectional streaming with LiveRequestQueue"
	@echo "   âš ï¸  Requires Vertex AI authentication (not API keys)"
	@echo "   ğŸŒ Default region: us-central1; export GOOGLE_CLOUD_LOCATION to change"
	@echo "   ğŸ”„ Sends one message and shows real-time text response"
	@echo "   ğŸ“¡ Uses Live API for low-latency conversation"
	python -m voice_assistant.basic_demo --text

# Basic demo with AUDIO modality (requires PyAudio)
basic_demo_audio: live_env_check audio_deps_check
	@echo "ğŸ¯ Running Basic Live API Demo (AUDIO MODE)..."
	@echo "   Demonstrates bidirectional streaming with audio playback"
	@echo "   âš ï¸  Requires: Vertex AI + PyAudio + Speakers"
	@echo "   ğŸŒ Default region: us-central1"
	@echo "   ğŸ”„ Sends text message, receives and plays audio response"
	@echo "   ğŸ”Š Audio output will play through your speakers"
	@echo "   ğŸ“¡ Uses native audio Live API model"
	python -m voice_assistant.basic_demo --audio

# Alias for backward compatibility (defaults to text mode)
basic_demo: basic_demo_text

# Direct Live API demo (bypasses ADK Runner - true audio input/output)
direct_audio_demo: live_env_check audio_deps_check
	@echo "ğŸ™ï¸  Running Direct Live API Audio Demo..."
	@echo "   TRUE bidirectional audio using google.genai.Client"
	@echo "   âš ï¸  Requires: Vertex AI + PyAudio + Microphone + Speakers"
	@echo "   ğŸ™ï¸  Microphone input â†’ Agent â†’ Speaker output"
	@echo "   âš¡ Bypasses ADK Runner (no agent tools/state)"
	@echo "   ğŸ“¡ Uses direct Live API WebSocket connection"
	@echo ""
	@echo "ğŸ’¡ This is the only way to get true audio input with current ADK"
	@echo "   ADK Runner.run_live() only supports text input + audio output"
	@echo ""
	python -m voice_assistant.direct_live_audio

live_models_list:
	@echo "ğŸ“¡ Querying Vertex AI for accessible Live API models..."
	@if [ -z "$$GOOGLE_GENAI_USE_VERTEXAI" ]; then \
		echo "   âŒ GOOGLE_GENAI_USE_VERTEXAI is not set. Export it to use Vertex AI."; \
		echo "   ğŸ‘‰ Example: export GOOGLE_GENAI_USE_VERTEXAI=1"; \
		exit 1; \
	fi
	@if [ -z "$$GOOGLE_CLOUD_PROJECT" ]; then \
		echo "   âŒ GOOGLE_CLOUD_PROJECT is missing. Set your Vertex project id."; \
		echo "   ğŸ‘‰ Example: export GOOGLE_CLOUD_PROJECT=your-project"; \
		exit 1; \
	fi
	@python -m scripts.list_live_models

# Individual demo commands
basic_demo: live_env_check
	@echo "ğŸ¯ Running Basic Live API Demo..."
	@echo "   Demonstrates fundamental bidirectional streaming with LiveRequestQueue"
	@echo "   âš ï¸  Requires Vertex AI authentication (not API keys)"
	@echo "   ğŸŒ Default region: $${GOOGLE_CLOUD_LOCATION:-us-central1}; export GOOGLE_CLOUD_LOCATION to change"
	@echo "   ğŸ”„ Sends one message and shows real-time streaming response"
	@echo "   ğŸ¤ Configured for voice output (Puck voice) but shows text responses"
	@echo "   ğŸ“¡ Uses Live API for low-latency conversation"
	python -m voice_assistant.basic_demo
	@echo "âœ… Basic demo completed!"

advanced_demo:
	@echo "âš¡ Running Advanced Features Demo..."
	@echo "   Shows proactivity, affective dialog, and video streaming concepts"
	python -m voice_assistant.advanced
	@echo "âœ… Advanced demo completed!"

multi_demo:
	@echo "ğŸ‘¥ Running Multi-Agent Voice Demo..."
	@echo "   Demonstrates coordinated voice agents with sequential workflow"
	python -m voice_assistant.multi_agent
	@echo "âœ… Multi-agent demo completed!"

interactive_demo: live_env_check audio_deps_check
	@echo "ğŸ¤ Running Interactive Voice Demo..."
	@echo "âš ï¸  This requires a microphone and PyAudio!"
	@echo "ğŸ’¡ Install PyAudio: pip install pyaudio"
	@echo "   (May require system audio libraries on some platforms)"
	python -m voice_assistant.interactive
	@echo "âœ… Interactive demo completed!"

live_audio_demo: interactive_demo
	@:

# Run all demos sequentially
all_demos:
	@echo "ğŸª Running ALL voice assistant demos..."
	@echo "=========================================="
	$(MAKE) demo
	@echo ""
	$(MAKE) basic_demo
	@echo ""
	$(MAKE) advanced_demo
	@echo ""
	$(MAKE) multi_demo
	@echo ""
	@echo "ğŸ‰ All demos completed!"
	@echo "ğŸ’¡ For voice interaction: make interactive_demo (requires microphone)"
	@echo "ğŸ”§ Pro tip: Run individual demos with 'make <demo_name>'"

# Code quality
lint:
	@echo "ğŸ” Running code quality checks..."
	@command -v ruff >/dev/null 2>&1 && ruff check voice_assistant/ tests/ || echo "âš ï¸  ruff not installed (optional)"
	@command -v mypy >/dev/null 2>&1 && mypy voice_assistant/ || echo "âš ï¸  mypy not installed (optional)"
	@command -v flake8 >/dev/null 2>&1 && flake8 voice_assistant/ tests/ || echo "âš ï¸  flake8 not installed (optional)"
	@echo "âœ… Lint checks complete!"

format:
	@echo "ğŸ¨ Formatting code..."
	@command -v black >/dev/null 2>&1 && black voice_assistant/ tests/ || echo "âš ï¸  black not installed (optional)"
	@echo "âœ… Code formatting complete!"

# Comprehensive validation
validate: lint test
	@echo "âœ… Full validation complete!"

# Clean up
clean:
	@echo "ğŸ§¹ Cleaning up cache files and artifacts..."
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	find . -type f -name "*.pyo" -delete
	find . -type f -name "*.pyd" -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	find . -type d -name ".pytest_cache" -exec rm -rf {} +
	find . -type d -name ".coverage" -exec rm -rf {} +
	find . -type f -name ".coverage" -delete
	find . -type f -name "coverage.xml" -delete
	@echo "âœ… Cleanup completed!"
