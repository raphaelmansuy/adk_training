.PHONY: help setup clean test demo dev evaluate

help:
	@echo "Tool Use Quality Evaluation TIL - Available Commands"
	@echo "====================================================="
	@echo ""
	@echo "make setup       Install dependencies and prepare environment"
	@echo "make test        Run unit tests (validates configuration)"
	@echo "make evaluate    Show LlmAsJudge with RUBRIC_BASED_TOOL_USE_QUALITY_V1"
	@echo "make dev         Launch ADK web interface to test tool use"
	@echo "make demo        Quick validation without web interface"
	@echo "make clean       Remove cache files and artifacts"
	@echo ""

setup:
	pip install -r requirements.txt
	pip install -e .
	cp tool_use_evaluator/.env.example tool_use_evaluator/.env
	@echo ""
	@echo "âœ… Setup complete!"
	@echo ""
	@echo "Next steps:"
	@echo "1. Add your GOOGLE_API_KEY to tool_use_evaluator/.env"
	@echo "2. Run 'make test' to validate the implementation"
	@echo "3. Run 'make dev' to launch web interface"
	@echo ""

dev:
	@echo ""
	@echo "ðŸš€ Launching ADK web interface..."
	@echo ""
	@echo "ðŸ“ How to test Tool Use Quality:"
	@echo "   1. Open http://localhost:8000"
	@echo "   2. Select 'tool_use_evaluator'"
	@echo "   3. Try these prompts:"
	@echo ""
	@echo "   âœ… GOOD TOOL USAGE:"
	@echo "   'Analyze customer_data, extract features, validate quality, then apply random_forest model'"
	@echo ""
	@echo "   âŒ BAD TOOL USAGE (out of order):"
	@echo "   'Apply the model first, then analyze the data, then extract features'"
	@echo ""
	@echo "   âœ… GOOD TOOL SEQUENCE:"
	@echo "   'Analyze sales_data, extract important features, validate them, apply gradient_boosting'"
	@echo ""
	@echo "ðŸ’¡ What to observe:"
	@echo "   â€¢ Tool call sequence in Events tab"
	@echo "   â€¢ Whether tools are called in logical order"
	@echo "   â€¢ Whether prerequisites are met before dependent tools"
	@echo "   â€¢ Error handling when tools are misused"
	@echo ""
	@echo "ðŸŽ¯ Evaluation Focus:"
	@echo "   This agent demonstrates tool use quality concepts:"
	@echo "   - Tool sequencing (analyze â†’ extract â†’ validate â†’ apply)"
	@echo "   - Tool dependencies (each step builds on previous)"
	@echo "   - Error handling (proper validation)"
	@echo "   - Efficiency (no skipped or redundant steps)"
	@echo ""
	adk web

test:
	@echo ""
	@echo "ðŸ§ª Running Tool Use Quality Evaluation Tests..."
	@echo ""
	@pytest tests/ -v --tb=short
	@echo ""
	@echo "âœ… Tests validate:"
	@echo "   â€¢ Agent configuration (6 tests)"
	@echo "   â€¢ Tool functionality (8 tests)"
	@echo "   â€¢ Import paths (3 tests)"
	@echo "   â€¢ App structure (3 tests)"
	@echo ""
	@echo "ðŸ“‹ Test Coverage:"
	@echo "   âœ“ Agent name, model, description, instruction"
	@echo "   âœ“ Agent has all 4 tools: analyze, extract, validate, apply"
	@echo "   âœ“ Agent has output_key configured"
	@echo "   âœ“ Tool success and error cases"
	@echo "   âœ“ Module imports and exports"
	@echo "   âœ“ App configuration and initialization"
	@echo ""
	@echo "ðŸ” What each test verifies:"
	@echo "   Agent Configuration Tests:"
	@echo "     - Agent name: tool_use_evaluator"
	@echo "     - Model: gemini-2.0-flash"
	@echo "     - Instruction emphasizes proper tool sequencing"
	@echo "     - All 4 tools are available"
	@echo ""
	@echo "   Tool Functionality Tests:"
	@echo "     - analyze_data handles success and error cases"
	@echo "     - extract_features validates input"
	@echo "     - validate_quality checks prerequisites"
	@echo "     - apply_model requires both features and model"
	@echo ""
	@echo "   Import & Structure Tests:"
	@echo "     - Agent can be imported from package"
	@echo "     - App configuration is correct"
	@echo "     - Module exports are properly set up"
	@echo ""
	@echo "ðŸ’¡ To run specific test:"
	@echo "   pytest tests/test_agent.py::TestAgentConfiguration -v"
	@echo "   pytest tests/test_agent.py::TestToolFunctionality -v"
	@echo ""
	@echo "ðŸ“Š To see test coverage:"
	@echo "   pytest tests/ --cov=tool_use_evaluator --cov-report=html"
	@echo ""

demo:
	@echo ""
	@echo "ðŸ” Quick validation..."
	python -c "from tool_use_evaluator import root_agent; from app import app; print('âœ… Agent loaded:', root_agent.name); print('âœ… App configured:', app.name); print('âœ… Tools count:', len(root_agent.tools)); print('âœ… Implementation ready!')"
	@echo ""
	@echo "ðŸŽ¯ Implementation is ready for evaluation!"
	@echo ""

evaluate:
	@echo ""
	@echo "ðŸ“Š Demonstrating LlmAsJudge with RUBRIC_BASED_TOOL_USE_QUALITY_V1"
	@echo ""
	python evaluate_tool_use.py
	@echo ""

clean:
	find . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name .pytest_cache -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete
	rm -rf .coverage htmlcov build dist *.egg-info
	@echo "âœ… Cleaned up cache files"
